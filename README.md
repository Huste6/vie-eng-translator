# ğŸŒ Dá»± Ãn Dá»‹ch Thuáº­t Tiáº¿ng Anh - Tiáº¿ng Viá»‡t vá»›i LSTM

Dá»± Ã¡n Machine Learning dá»‹ch thuáº­t tá»« Tiáº¿ng Anh sang Tiáº¿ng Viá»‡t sá»­ dá»¥ng máº¡ng LSTM (Long Short-Term Memory) vá»›i kiáº¿n trÃºc Encoder-Decoder.

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
vie-eng-translator/
â”‚
â”œâ”€â”€ data.txt                    # Dataset Tiáº¿ng Anh - Tiáº¿ng Viá»‡t
â”œâ”€â”€ train_model.py             # File huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”œâ”€â”€ inference.py               # File dá»± Ä‘oÃ¡n/dá»‹ch thuáº­t
â”œâ”€â”€ gui_translator.py          # Giao diá»‡n ngÆ°á»i dÃ¹ng (Tkinter)
â”œâ”€â”€ requirements.txt           # ThÆ° viá»‡n cáº§n thiáº¿t
â”œâ”€â”€ README.md                  # HÆ°á»›ng dáº«n
â”‚
â””â”€â”€ models/                    # ThÆ° má»¥c chá»©a mÃ´ hÃ¬nh Ä‘Ã£ train
    â”œâ”€â”€ vie_eng_translator.h5  # MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    â””â”€â”€ training_data.pkl      # Dá»¯ liá»‡u training (metadata)
```

## ğŸ¯ TÃ­nh NÄƒng

âœ… **MÃ´ hÃ¬nh LSTM 3 lá»›p**: Sá»­ dá»¥ng 3 lá»›p LSTM cho cáº£ Encoder vÃ  Decoder  
âœ… **Dropout**: TrÃ¡nh overfitting vá»›i Dropout layers  
âœ… **Teacher Forcing**: Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c khi training  
âœ… **One-hot Encoding**: Vector hÃ³a kÃ½ tá»±  
âœ… **GUI thÃ¢n thiá»‡n**: Giao diá»‡n Tkinter Ä‘áº¹p máº¯t vÃ  dá»… sá»­ dá»¥ng  
âœ… **Batch Processing**: Xá»­ lÃ½ nhiá»u cÃ¢u cÃ¹ng lÃºc

## ğŸ› ï¸ Kiáº¿n TrÃºc MÃ´ HÃ¬nh

### Encoder (3 lá»›p LSTM):
```
Input â†’ LSTM1(256) â†’ Dropout(0.2) â†’ 
        LSTM2(256) â†’ Dropout(0.2) â†’ 
        LSTM3(256) â†’ [state_h, state_c]
```

### Decoder (3 lá»›p LSTM):
```
Input + Encoder States â†’ LSTM1(256) â†’ Dropout(0.2) â†’ 
                          LSTM2(256) â†’ Dropout(0.2) â†’ 
                          LSTM3(256) â†’ Dense(softmax)
```

## ğŸ“‹ YÃªu Cáº§u Há»‡ Thá»‘ng

- Python 3.8+
- TensorFlow 2.13+
- NumPy 1.24+
- Scikit-learn 1.3+
- Tkinter (cÃ³ sáºµn vá»›i Python)

## ğŸš€ CÃ i Äáº·t

### 1. Clone hoáº·c táº£i dá»± Ã¡n
```bash
git clone <your-repo-url>
cd vie-eng-translator
```

### 2. Táº¡o vÃ  kÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o (Virtual Environment)

**TrÃªn Windows:**
```bash
# Táº¡o virtual environment
python -m venv venv

# KÃ­ch hoáº¡t venv
venv\Scripts\activate
```

**TrÃªn Linux/macOS:**
```bash
# Táº¡o virtual environment
python3 -m venv venv

# KÃ­ch hoáº¡t venv
source venv/bin/activate
```

> ğŸ’¡ **LÆ°u Ã½**: Sau khi kÃ­ch hoáº¡t, báº¡n sáº½ tháº¥y `(venv)` xuáº¥t hiá»‡n á»Ÿ Ä‘áº§u dÃ²ng lá»‡nh.

### 3. CÃ i Ä‘áº·t thÆ° viá»‡n
```bash
pip install -r requirements.txt
```

### 4. Chuáº©n bá»‹ dataset
Äáº£m báº£o file `data.txt` cÃ³ format:
```
English sentence<TAB>Vietnamese sentence
```

VÃ­ dá»¥:
```
Run!	Cháº¡y!
Help!	GiÃºp tÃ´i vá»›i!
Stop!	Dá»«ng láº¡i!
```

## ğŸ“š HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### BÆ°á»›c 1: Huáº¥n Luyá»‡n MÃ´ HÃ¬nh
```bash
python train_model.py
```

Tham sá»‘ cÃ³ thá»ƒ tÃ¹y chá»‰nh trong file:
- `num_samples`: Sá»‘ lÆ°á»£ng máº«u training (None = táº¥t cáº£)
- `epochs`: Sá»‘ epoch (máº·c Ä‘á»‹nh: 100)
- `batch_size`: KÃ­ch thÆ°á»›c batch (máº·c Ä‘á»‹nh: 64)
- `latent_dim`: Sá»‘ neurons trong LSTM (máº·c Ä‘á»‹nh: 256)
- `validation_split`: Tá»· lá»‡ validation (máº·c Ä‘á»‹nh: 0.2)

**Output:**
- âœ… `models/vie_eng_translator.h5`
- âœ… `models/training_data.pkl`

### BÆ°á»›c 2: Kiá»ƒm Tra MÃ´ HÃ¬nh (Terminal)
```bash
python inference.py
```
Sáº½ test vá»›i má»™t sá»‘ cÃ¢u máº«u vÃ  hiá»ƒn thá»‹ káº¿t quáº£ dá»‹ch.

### BÆ°á»›c 3: Cháº¡y Giao Diá»‡n
```bash
python gui_translator.py
```

TÃ­nh nÄƒng GUI:
- âœ¨ Nháº­p vÄƒn báº£n tiáº¿ng Anh
- ğŸ”„ Nháº¥n "Dá»‹ch" hoáº·c Ctrl+Enter
- ğŸ“ Xem káº¿t quáº£ tiáº¿ng Viá»‡t
- ğŸ—‘ï¸ XÃ³a vÃ  dá»‹ch láº¡i

## ğŸ’¡ Tips Tá»‘i Æ¯u

### 1. TÄƒng Ä‘á»™ chÃ­nh xÃ¡c:
- TÄƒng sá»‘ lÆ°á»£ng dá»¯ liá»‡u training
- TÄƒng sá»‘ epochs (200-300)
- Thá»­ nghiá»‡m vá»›i latent_dim khÃ¡c (128, 512)
- ThÃªm nhiá»u lá»›p LSTM hÆ¡n

### 2. Giáº£m overfitting:
- TÄƒng Dropout rate (0.3-0.5)
- TÄƒng validation_split (0.25-0.3)
- Sá»­ dá»¥ng Early Stopping

### 3. TÄƒng tá»‘c training:
- Giáº£m batch_size náº¿u GPU bá»‹ háº¿t RAM
- Sá»­ dá»¥ng GPU thay vÃ¬ CPU
- Giáº£m max_input_length vÃ  max_target_length

## ğŸ“Š Káº¿t Quáº£ Mong Äá»£i

### Vá»›i dataset nhá» (~100 cÃ¢u):
- Training Accuracy: 80-95%
- Validation Accuracy: 70-85%
- Training Time: 5-15 phÃºt (tÃ¹y CPU/GPU)

### Vá»›i dataset lá»›n (10,000+ cÃ¢u):
- Training Accuracy: 95-99%
- Validation Accuracy: 85-95%
- Training Time: 2-5 giá» (tÃ¹y hardware)

## ğŸ”§ Troubleshooting

### Lá»—i: "Out of Memory"
```python
# Trong train_model.py, giáº£m:
batch_size = 32  # thay vÃ¬ 64
latent_dim = 128  # thay vÃ¬ 256
```

### Lá»—i: Model khÃ´ng load Ä‘Æ°á»£c
```bash
# Kiá»ƒm tra file tá»“n táº¡i
ls models/
# Pháº£i cÃ³: vie_eng_translator.h5 vÃ  training_data.pkl
```

### Lá»—i: Dá»‹ch khÃ´ng chÃ­nh xÃ¡c
- Train thÃªm epochs
- ThÃªm dá»¯ liá»‡u training
- Kiá»ƒm tra dataset cÃ³ Ä‘Ãºng format khÃ´ng

## ğŸ“– Giáº£i ThÃ­ch Code

### train_model.py
- `load_dataset()`: Äá»c vÃ  parse dataset
- `vectorize_data()`: Chuyá»ƒn text thÃ nh vector
- `build_model()`: XÃ¢y dá»±ng mÃ´ hÃ¬nh LSTM 3 lá»›p
- `train_model()`: Huáº¥n luyá»‡n mÃ´ hÃ¬nh
- `save_model_and_data()`: LÆ°u mÃ´ hÃ¬nh vÃ  metadata

### inference.py
- `Translator.__init__()`: Load mÃ´ hÃ¬nh Ä‘Ã£ train
- `_build_encoder_model()`: Táº¡o encoder Ä‘á»ƒ extract states
- `_build_decoder_model()`: Táº¡o decoder Ä‘á»ƒ generate output
- `translate()`: Dá»‹ch vÄƒn báº£n

### gui_translator.py
- Giao diá»‡n Tkinter vá»›i threading
- Load mÃ´ hÃ¬nh báº¥t Ä‘á»“ng bá»™
- Há»— trá»£ dá»‹ch nhiá»u cÃ¢u

## ğŸ“ Kiáº¿n Thá»©c Cáº§n Thiáº¿t

- **LSTM**: Hiá»ƒu cÃ¡ch LSTM hoáº¡t Ä‘á»™ng
- **Seq2Seq**: Kiáº¿n trÃºc Encoder-Decoder
- **One-hot Encoding**: Vector hÃ³a dá»¯ liá»‡u
- **Teacher Forcing**: Ká»¹ thuáº­t training
- **Keras/TensorFlow**: API cá»§a TensorFlow

## ğŸ¤ ÄÃ³ng GÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! HÃ£y táº¡o Pull Request hoáº·c Issue.

## ğŸ“„ License

MIT License - Tá»± do sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.

## ğŸ‘¨â€ğŸ’» TÃ¡c Giáº£

Dá»± Ã¡n Machine Learning - Dá»‹ch Thuáº­t Tiáº¿ng Anh - Tiáº¿ng Viá»‡t

---

**ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰**
